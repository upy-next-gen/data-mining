# Reporte de Procesamiento de Datos ENSU - Yucat√°n

**Proyecto:** An√°lisis de Percepci√≥n de Inseguridad en Yucat√°n  
**Fuente:** Encuesta Nacional de Seguridad Urbana (ENSU) 2015-2025  
**Fecha:** 14 de Septiembre de 2025  
**Estudiante:** This
**Materia:** Data Mining  

---

## üìã Resumen Ejecutivo

Este proyecto implement√≥ un pipeline completo de procesamiento de datos para analizar la percepci√≥n de seguridad en municipios de Yucat√°n utilizando datos de la Encuesta Nacional de Seguridad Urbana (ENSU) del INEGI, abarcando el per√≠odo 2015-2025. El proceso incluy√≥ descubrimiento automatizado de archivos, limpieza de datos, normalizaci√≥n de texto, y unificaci√≥n en un dataset consolidado para an√°lisis posterior.

### Resultados Principales
- **42 archivos CB identificados** de un total de >80 datasets ENSU
- **33 archivos procesados exitosamente** (2016-2025)
- **127 registros consolidados** representando 8,703 encuestas
- **4 municipios analizados:** M√©rida, Kanas√≠n, Progreso, Um√°n
- **Dataset final unificado** listo para an√°lisis de miner√≠a de datos

---

## üéØ Objetivos del Proyecto

### Objetivo General
Procesar y consolidar datos de percepci√≥n de seguridad de la ENSU para municipios de Yucat√°n, preparando un dataset estructurado para an√°lisis de patrones temporales de inseguridad urbana.

### Objetivos Espec√≠ficos
1. **Mapear** la estructura de datos ENSU en el repositorio local
2. **Identificar** archivos CB (Cuestionario B√°sico) relevantes para el an√°lisis
3. **Extraer** datos espec√≠ficos de Yucat√°n con variables de inter√©s
4. **Procesar** informaci√≥n de percepci√≥n de seguridad (BP1_1)
5. **Normalizar** nombres de entidades y municipios
6. **Unificar** datos en un dataset consolidado cronol√≥gicamente ordenado

---

## üîÑ Metodolog√≠a y Flujo de Trabajo

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  DESCUBRIMIENTO ‚îÇ    ‚îÇ   PROCESAMIENTO ‚îÇ    ‚îÇ   UNIFICACI√ìN   ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ Mapeo de      ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Filtrado      ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Consolidaci√≥n ‚îÇ
‚îÇ   estructura    ‚îÇ    ‚îÇ   Yucat√°n       ‚îÇ    ‚îÇ   temporal      ‚îÇ
‚îÇ ‚Ä¢ Identificaci√≥n‚îÇ    ‚îÇ ‚Ä¢ An√°lisis      ‚îÇ    ‚îÇ ‚Ä¢ Validaci√≥n    ‚îÇ
‚îÇ   archivos CB   ‚îÇ    ‚îÇ   percepci√≥n    ‚îÇ    ‚îÇ   duplicados    ‚îÇ
‚îÇ ‚Ä¢ Validaci√≥n    ‚îÇ    ‚îÇ ‚Ä¢ Normalizaci√≥n ‚îÇ    ‚îÇ ‚Ä¢ Estad√≠sticas  ‚îÇ
‚îÇ   contenido     ‚îÇ    ‚îÇ   texto         ‚îÇ    ‚îÇ   resumen       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚ñ≤                        ‚ñ≤                        ‚ñ≤
        ‚îÇ                        ‚îÇ                        ‚îÇ
   Raw Data                 Individual               Unified
   (80+ files)              CSV Files               Dataset
                           (33 files)              (127 records)
```

---

## üìä Fases del Proyecto

### **FASE 1: Descubrimiento y Exploraci√≥n de Datos**

#### Solicitud Inicial
> "Necesito mapear la informaci√≥n que se encuentra en la carpeta data"

#### Proceso Implementado
1. **Exploraci√≥n inicial** de la estructura de directorios
2. **Identificaci√≥n de patrones** en nombres de archivos ENSU
3. **B√∫squeda espec√≠fica** de archivos CB (Cuestionario B√°sico)
4. **Validaci√≥n de contenido** y estructura de datos

#### C√≥digo Clave - Descubrimiento de Archivos
```python
def find_cb_datasets(base_path):
    """Encuentra todos los archivos CB en la estructura ENSU"""
    cb_files = []
    for root, dirs, files in os.walk(base_path):
        if '/conjunto_de_datos_' in root and 'cb' in root.lower():
            for file in files:
                if file.endswith('.csv') and 'cb' in file.lower():
                    cb_files.append(os.path.join(root, file))
    return sorted(cb_files)
```

#### Resultados Fase 1
- **42 archivos CB identificados** en estructura jer√°rquica
- **Patr√≥n temporal detectado:** 2015-2025 con gaps en algunos trimestres
- **Estructura de columnas validada:** NOM_ENT, NOM_MUN, BP1_1

---

### **FASE 2: Procesamiento de Datos Individuales**

#### Solicitud de Procesamiento
> "Procesa cada archivo y extrae solo los datos de Yucat√°n con las columnas NOM_ENT, NOM_MUN, BP1_1"

#### Desaf√≠os Encontrados y Soluciones

##### **Problema 1: Codificaci√≥n de Caracteres**
```
Error: 'utf-8' codec can't decode byte 0xf1 in position X
```
**Soluci√≥n Implementada:**
```python
def load_csv_with_fallback_encoding(file_path):
    encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']
    for encoding in encodings:
        try:
            return pd.read_csv(file_path, encoding=encoding, low_memory=False)
        except UnicodeDecodeError:
            continue
    raise ValueError(f"No se pudo decodificar el archivo: {file_path}")
```

##### **Problema 2: Caracteres de Control en Texto**
```
Municipio detectado: "MERIDA\r" con caracteres extra√±os
```
**Soluci√≥n Implementada:**
```python
def normalize_text(text):
    """Normaliza texto removiendo acentos y caracteres especiales"""
    if pd.isna(text):
        return text
    text = str(text).strip()
    text = unicodedata.normalize('NFD', text)
    text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
    return text.replace('√ë', 'N').replace('√±', 'n')
```

##### **Problema 3: Archivos de Diccionario**
```
Warning: Archivo detectado como diccionario, omitiendo procesamiento
```
**Soluci√≥n Implementada:**
```python
def is_dictionary_file(df):
    """Detecta si el archivo es un diccionario de datos"""
    dict_indicators = ['DESCRIPCION', 'DESCRIPCI√ìN', 'ETIQUETA', 'VALORES']
    return any(col.upper() in dict_indicators for col in df.columns)
```

#### C√≥digo Principal - Procesamiento
```python
def process_security_perception(df):
    """Procesa la percepci√≥n de seguridad BP1_1"""
    security_stats = {
        'TOTAL_SEGUROS': len(df[df['BP1_1'] == 1]),      # Seguro
        'TOTAL_INSEGUROS': len(df[df['BP1_1'] == 2]),    # Inseguro  
        'TOTAL_NO_RESPONDE': len(df[df['BP1_1'].isin([8, 9])])  # No sabe/No responde
    }
    
    total = sum(security_stats.values())
    if total > 0:
        security_stats.update({
            'PCT_SEGUROS': round((security_stats['TOTAL_SEGUROS'] / total) * 100, 2),
            'PCT_INSEGUROS': round((security_stats['TOTAL_INSEGUROS'] / total) * 100, 2),
            'PCT_NO_RESPONDE': round((security_stats['TOTAL_NO_RESPONDE'] / total) * 100, 2)
        })
    
    return security_stats
```

#### Resultados Fase 2
- **33 archivos procesados exitosamente** (de 42 identificados)
- **9 archivos omitidos:** 7 por ser diccionarios, 2 por errores de estructura
- **Formato de salida estandarizado:** `procesado_YYYY_QQT_cb.csv`

---

### **FASE 3: Unificaci√≥n de Datos**

#### Solicitud de Unificaci√≥n
> "Ahora unifica los datos extra√≠dos en un solo archivo para poder generar un reporte"

#### Proceso de Consolidaci√≥n

##### **Detecci√≥n de Archivos Procesados**
```python
def find_processed_files(directory):
    """Encuentra todos los archivos procesados con patr√≥n espec√≠fico"""
    pattern = r'procesado_\d{4}_\d{2}T_cb\.csv'
    processed_files = []
    
    for file in os.listdir(directory):
        if re.match(pattern, file):
            processed_files.append(os.path.join(directory, file))
    
    return sorted(processed_files)
```

##### **Validaci√≥n de Duplicados**
```python
def detect_duplicates(df):
    """Detecta registros duplicados en el dataset unificado"""
    duplicate_cols = ['NOM_ENT', 'NOM_MUN', 'ANO', 'TRIMESTRE']
    duplicates = df[df.duplicated(subset=duplicate_cols, keep=False)]
    
    if not duplicates.empty:
        logging.warning(f"Se encontraron {len(duplicates)} registros duplicados")
        return duplicates
    else:
        logging.info("No se encontraron registros duplicados")
        return pd.DataFrame()
```

##### **Ordenamiento Cronol√≥gico**
```python
def sort_data_chronologically(df):
    """Ordena datos cronol√≥gicamente por a√±o y trimestre"""
    df_sorted = df.sort_values(['ANO', 'TRIMESTRE', 'NOM_MUN']).reset_index(drop=True)
    logging.info("Datos ordenados cronol√≥gicamente (m√°s antiguos primero)")
    return df_sorted
```

#### Resultados Fase 3
- **127 registros consolidados** sin duplicados
- **Per√≠odo:** 2016 Q4 - 2025 Q2 
- **8,703 encuestas** analizadas en total
- **Orden cronol√≥gico** mantenido para an√°lisis temporal

---

## üìà Resultados y Estad√≠sticas Finales

### Cobertura Temporal
| A√±o  | Registros | Trimestres Disponibles |
|------|-----------|------------------------|
| 2016 | 4         | Q4                     |
| 2017 | 16        | Q1, Q2, Q3, Q4         |
| 2018 | 16        | Q1, Q2, Q3, Q4         |
| 2019 | 12        | Q2, Q3, Q4             |
| 2020 | 12        | Q1, Q3, Q4             |
| 2021 | 16        | Q1, Q2, Q3, Q4         |
| 2022 | 16        | Q1, Q2, Q3, Q4         |
| 2023 | 12        | Q1, Q2, Q3, Q4         |
| 2024 | 15        | Q1, Q2, Q3, Q4         |
| 2025 | 8         | Q1, Q2                 |

### Cobertura Municipal
| Municipio | Registros | Observaci√≥n |
|-----------|-----------|-------------|
| M√©rida    | 33        | Cobertura completa |
| Kanas√≠n   | 33        | Cobertura completa |
| Progreso  | 33        | Cobertura completa |
| Um√°n      | 28        | Faltantes en algunos per√≠odos |

**Total:** 4 municipios, 127 registros temporales

### Indicadores de Seguridad Global
- **Promedio de percepci√≥n de seguridad:** 59.76%
- **Promedio de percepci√≥n de inseguridad:** 40.23%
- **No respuesta promedio:** 0.01%

---

## üíª Logs de Ejecuci√≥n Principales

### Log de Procesamiento Exitoso
```
2025-09-14 17:13:15,432 - INFO - Iniciando procesamiento de archivo: conjunto_de_datos_ensu_2024_3t_csv/cb.csv
2025-09-14 17:13:15,468 - INFO - Archivo cargado exitosamente. Shape: (1520, 87)
2025-09-14 17:13:15,469 - INFO - Datos de Yucat√°n encontrados: 258 registros
2025-09-14 17:13:15,470 - INFO - Municipios √∫nicos en Yucat√°n: ['KANASIN', 'MERIDA', 'PROGRESO', 'UMAN']
2025-09-14 17:13:15,472 - INFO - Estad√≠sticas por municipio procesadas correctamente
2025-09-14 17:13:15,473 - INFO - Archivo guardado: procesado_2024_03T_cb.csv
```

### Log de Unificaci√≥n Final
```
2025-09-14 17:19:36,713 - INFO - RESUMEN FINAL DE LA UNIFICACI√ìN
2025-09-14 17:19:36,713 - INFO - Archivos procesados: 33
2025-09-14 17:19:36,713 - INFO - Total de registros: 127
2025-09-14 17:19:36,713 - INFO - Municipios √∫nicos: 8
2025-09-14 17:19:36,713 - INFO - Per√≠odo: 2016Q1 - 2025Q4
2025-09-14 17:19:36,713 - INFO - Total de encuestas: 8,703
2025-09-14 17:19:36,713 - INFO - Promedio de seguridad: 59.76%
2025-09-14 17:19:36,713 - INFO - Promedio de inseguridad: 40.23%
```

---

## üîß Herramientas y Tecnolog√≠as Utilizadas

### Stack Tecnol√≥gico
- **Python 3.x** - Lenguaje de programaci√≥n principal
- **pandas 2.3.2** - Manipulaci√≥n y an√°lisis de datos
- **uv** - Gesti√≥n de entorno virtual y dependencias
- **logging** - Sistema de registro de operaciones
- **unicodedata** - Normalizaci√≥n de texto Unicode
- **pathlib/os** - Manejo de sistema de archivos
- **re** - Procesamiento de expresiones regulares

### Estructura de Archivos Generados
```
data-mining/
‚îú‚îÄ‚îÄ process_yucatan_insecurity.py      # Script principal de procesamiento
‚îú‚îÄ‚îÄ unify_yucatan_data.py              # Script de unificaci√≥n
‚îú‚îÄ‚îÄ data/yucatan-inseguridad/
‚îÇ   ‚îú‚îÄ‚îÄ procesado_YYYY_QQT_cb.csv     # 33 archivos procesados
‚îÇ   ‚îú‚îÄ‚îÄ data-yucatan-inseguridad.csv  # Dataset unificado final
‚îÇ   ‚îú‚îÄ‚îÄ procesamiento_yucatan.log     # Log de procesamiento
‚îÇ   ‚îî‚îÄ‚îÄ unificacion_yucatan.log       # Log de unificaci√≥n
‚îî‚îÄ‚îÄ reporte_procesamiento.md          # Este reporte
```

---

## üìö Lecciones Aprendidas

### Desaf√≠os T√©cnicos Superados
1. **Heterogeneidad de codificaci√≥n** en archivos gubernamentales
2. **Inconsistencias en estructura** entre a√±os de la ENSU
3. **Normalizaci√≥n de texto** para an√°lisis consistente
4. **Validaci√≥n de calidad** de datos autom√°tica

### Buenas Pr√°cticas Implementadas
1. **Logging comprehensivo** para trazabilidad
2. **Manejo de errores robusto** con fallbacks
3. **Validaci√≥n autom√°tica** de duplicados
4. **Separaci√≥n de concerns** (procesamiento vs unificaci√≥n)
5. **Documentaci√≥n en c√≥digo** para mantenibilidad

### Consideraciones para Data Mining
1. **Dataset balanceado** temporalmente para an√°lisis de series
2. **Variables categ√≥ricas** listas para encoding
3. **Datos num√©ricos** normalizados y validados
4. **Metadatos temporales** preservados para an√°lisis estacional

---

## üéØ Prompt de Replicabilidad

### Para Replicar el Proceso Completo:

```markdown
**CONTEXTO:** Tienes una carpeta "raw data" con datasets ENSU (Encuesta Nacional de Seguridad Urbana) 
del INEGI organizados por a√±o y trimestre. Necesitas procesar datos de percepci√≥n de seguridad 
para el estado de Yucat√°n.

**FASE 1 - DESCUBRIMIENTO:**
"Necesito mapear la informaci√≥n que se encuentra en la carpeta data. Busca espec√≠ficamente 
archivos que contengan 'cb' en su estructura de carpetas, estos corresponden al Cuestionario 
B√°sico de la ENSU. Identifica la estructura temporal y valida que contengan las columnas 
NOM_ENT, NOM_MUN, y BP1_1."

**FASE 2 - PROCESAMIENTO:**
"Procesa cada archivo CB identificado y extrae solo los datos de Yucat√°n. Para cada municipio 
y per√≠odo, calcula estad√≠sticas de la variable BP1_1 (percepci√≥n de seguridad): total de 
personas que se sienten seguras (valor 1), inseguras (valor 2), y no responden (valores 8,9). 
Calcula tambi√©n los porcentajes. Normaliza los nombres de municipios removiendo acentos y 
caracteres especiales. Guarda cada archivo procesado con formato 'procesado_YYYY_QQT_cb.csv'."

**FASE 3 - UNIFICACI√ìN:**
"Unifica todos los archivos procesados en un solo dataset cronol√≥gicamente ordenado. Detecta 
y reporta duplicados. Genera estad√≠sticas de resumen incluyendo cobertura temporal, municipal, 
y promedios de percepci√≥n de seguridad. Guarda el resultado como 'data-yucatan-inseguridad.csv'."

**HERRAMIENTAS REQUERIDAS:** Python con pandas, entorno virtual, sistema de logging.
**RESULTADO ESPERADO:** Dataset unificado listo para an√°lisis de miner√≠a de datos con 
127 registros cubriendo 4 municipios de Yucat√°n en el per√≠odo 2016-2025.
```

---

## üìã Siguientes Pasos

Este procesamiento ha preparado los datos para la **segunda fase del proyecto**: el an√°lisis de miner√≠a de datos propiamente dicho. El dataset unificado permitir√°:

1. **An√°lisis temporal** de tendencias de percepci√≥n de seguridad
2. **Comparaci√≥n intermunicipal** de patrones de inseguridad
3. **Modelado predictivo** de percepci√≥n de seguridad
4. **Clustering** de municipios por similitud en patrones
5. **An√°lisis estacional** de variaciones trimestrales

---

**Fin del Reporte de Procesamiento de Datos**  
*Preparado para: Materia de Data Mining*  
*Fecha: 14 de Septiembre de 2025*
